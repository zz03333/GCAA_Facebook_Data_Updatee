"""
Facebook ç¤¾ç¾¤æ•¸æ“šåˆ†ææ¡†æ¶ - å ±è¡¨æŸ¥è©¢å·¥å…·
æä¾›å¸¸ç”¨åˆ†ææŸ¥è©¢èˆ‡å ±è¡¨ç”¢å‡º
"""

import sqlite3
from datetime import datetime
from typing import Dict, List
from utils.config import DB_PATH


def get_connection():
    """å–å¾—è³‡æ–™åº«é€£ç·š"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


# ==================== ç™¼æ–‡æ™‚é–“åˆ†æ ====================

def get_best_posting_times(conn, limit: int = 10) -> List[Dict]:
    """
    æ‰¾å‡ºæœ€ä½³ç™¼æ–‡æ™‚é–“çµ„åˆ
    """
    cursor = conn.cursor()
    cursor.execute(""" 
        SELECT 
            pc.time_slot,
            CASE pc.day_of_week
                WHEN 0 THEN 'Mon'
                WHEN 1 THEN 'Tue'
                WHEN 2 THEN 'Wed'
                WHEN 3 THEN 'Thu'
                WHEN 4 THEN 'Fri'
                WHEN 5 THEN 'Sat'
                WHEN 6 THEN 'Sun'
            END as day_of_week,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.click_through_rate), 4) as avg_ctr
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY pc.time_slot, pc.day_of_week
        HAVING post_count >= 3
        ORDER BY avg_er DESC
        LIMIT ?
    """, (limit,))
    
    return [dict(row) for row in cursor.fetchall()]


def get_hourly_performance(conn) -> List[Dict]:
    """
    å–å¾—æ¯å°æ™‚çš„å¹³å‡è¡¨ç¾
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            pc.hour_of_day,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.click_through_rate), 4) as avg_ctr
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY pc.hour_of_day
        ORDER BY pc.hour_of_day
    """)
    
    return [dict(row) for row in cursor.fetchall()]


def get_best_posting_times_by_topic(conn, limit: int = 30) -> List[Dict]:
    """
    æ‰¾å‡ºå„è­°é¡Œçš„æœ€ä½³ç™¼æ–‡æ™‚é–“çµ„åˆ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COALESCE(pc.issue_topic, 'unclassified') as issue_topic,
            pc.time_slot,
            CASE pc.day_of_week
                WHEN 0 THEN 'Mon'
                WHEN 1 THEN 'Tue'
                WHEN 2 THEN 'Wed'
                WHEN 3 THEN 'Thu'
                WHEN 4 THEN 'Fri'
                WHEN 5 THEN 'Sat'
                WHEN 6 THEN 'Sun'
            END as day_of_week,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.click_through_rate), 4) as avg_ctr
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY issue_topic, pc.time_slot, pc.day_of_week
        ORDER BY issue_topic, avg_er DESC
    """)
    
    return [dict(row) for row in cursor.fetchall()]


def get_best_posting_times_by_format(conn, limit: int = 30) -> List[Dict]:
    """
    æ‰¾å‡ºå„è¡Œå‹•é¡å‹çš„æœ€ä½³ç™¼æ–‡æ™‚é–“çµ„åˆ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COALESCE(pc.format_type, pc.topic_primary, 'unclassified') as format_type,
            pc.time_slot,
            CASE pc.day_of_week
                WHEN 0 THEN 'Mon'
                WHEN 1 THEN 'Tue'
                WHEN 2 THEN 'Wed'
                WHEN 3 THEN 'Thu'
                WHEN 4 THEN 'Fri'
                WHEN 5 THEN 'Sat'
                WHEN 6 THEN 'Sun'
            END as day_of_week,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.click_through_rate), 4) as avg_ctr
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY format_type, pc.time_slot, pc.day_of_week
        ORDER BY format_type, avg_er DESC
    """)
    
    return [dict(row) for row in cursor.fetchall()]


def get_quadrant_analysis(conn) -> List[Dict]:
    """
    å–å¾—è±¡é™åˆ†æè³‡æ–™ï¼ˆç”¨æ–¼ Looker Studio è¦–è¦ºåŒ–ï¼‰
    Xè»¸ï¼šè§¸åŠäººæ•¸ (reach)
    Yè»¸ï¼šäº’å‹•ç‡ (engagement_rate)
    åŸºæº–ç·šï¼šä¸­ä½æ•¸
    """
    cursor = conn.cursor()
    
    # å…ˆè¨ˆç®—ä¸­ä½æ•¸
    cursor.execute("""
        WITH latest_snapshots AS (
            SELECT post_id, post_impressions_unique
            FROM post_insights_snapshots
            WHERE (post_id, fetch_date) IN (
                SELECT post_id, MAX(fetch_date) 
                FROM post_insights_snapshots 
                GROUP BY post_id
            )
        ),
        stats AS (
            SELECT 
                ls.post_impressions_unique as reach,
                pp.engagement_rate
            FROM posts_performance pp
            JOIN latest_snapshots ls ON pp.post_id = ls.post_id
            WHERE ls.post_impressions_unique > 0
        )
        SELECT 
            (SELECT reach FROM stats ORDER BY reach LIMIT 1 OFFSET (SELECT COUNT(*)/2 FROM stats)) as median_reach,
            (SELECT engagement_rate FROM stats ORDER BY engagement_rate LIMIT 1 OFFSET (SELECT COUNT(*)/2 FROM stats)) as median_er
    """)
    medians = cursor.fetchone()
    median_reach = medians['median_reach'] or 1000
    median_er = medians['median_er'] or 0.03
    
    # å–å¾—æ‰€æœ‰è²¼æ–‡è³‡æ–™ (ä½¿ç”¨æœ€æ–° snapshot)
    cursor.execute("""
        WITH latest_insights AS (
            SELECT post_id, post_impressions_unique
            FROM post_insights_snapshots
            WHERE (post_id, fetch_date) IN (
                SELECT post_id, MAX(fetch_date)
                FROM post_insights_snapshots
                GROUP BY post_id
            )
        ),
        latest_performance AS (
            SELECT post_id, engagement_rate
            FROM posts_performance
            WHERE (post_id, snapshot_date) IN (
                SELECT post_id, MAX(snapshot_date)
                FROM posts_performance
                GROUP BY post_id
            )
        )
        SELECT
            p.post_id,
            p.created_time,
            p.permalink_url,
            SUBSTR(p.message, 1, 50) as content_short,
            li.post_impressions_unique as reach,
            lp.engagement_rate,
            COALESCE(pc.issue_topic, 'unclassified') as topic_tag,
            COALESCE(pc.format_type, pc.topic_primary, 'unclassified') as format_type
        FROM posts p
        JOIN latest_performance lp ON p.post_id = lp.post_id
        JOIN posts_classification pc ON p.post_id = pc.post_id
        JOIN latest_insights li ON p.post_id = li.post_id
        WHERE li.post_impressions_unique > 0
        ORDER BY p.created_time DESC
    """)
    
    results = []
    for row in cursor.fetchall():
        d = dict(row)
        d['median_reach'] = median_reach
        d['median_er'] = median_er
        
        # è¨ˆç®—è±¡é™
        is_high_reach = d['reach'] >= median_reach
        is_high_er = d['engagement_rate'] >= median_er
        
        if is_high_reach and is_high_er:
            d['quadrant'] = 'ç‹ç‰Œè²¼æ–‡'
        elif not is_high_reach and is_high_er:
            d['quadrant'] = 'æ½›åŠ›çå¯¶'
        elif is_high_reach and not is_high_er:
            d['quadrant'] = 'å»£å‚³é™·é˜±'
        else:
            d['quadrant'] = 'å¸¸æ…‹å…§å®¹'
        
        results.append(d)
    
    return results


# ==================== ä¸»é¡Œåˆ†æ (é›™ç¶­åº¦) ====================

# å®šç¾©é¡¯ç¤ºåç¨±å°ç…§
FORMAT_TYPE_NAMES = {
    'event': 'å®šæœŸæ´»å‹•ï¼ˆå½±å±•ã€æ¼”è¬›ï¼‰',
    'press': 'è¨˜è€…æœƒ',
    'statement': 'å…¬é–‹ç™¼è¨€/è²æ˜ç¨¿',
    'opinion': 'æ–°èè§€é»',
    'op_ed': 'ç¶ ç›ŸæŠ•æ›¸',
    'report': 'å ±å‘Šç™¼å¸ƒ',
    'booth': 'æ“ºæ”¤è³‡è¨Š',
    'edu': 'ç§‘æ™®æ–‡ç« /Podcast',
    'action': 'å…¶ä»–è¡Œå‹•è™Ÿå¬',
}

ISSUE_TOPIC_NAMES = {
    'nuclear': 'æ ¸èƒ½ç™¼é›»',
    'climate': 'æ°£å€™å•é¡Œ',
    'net_zero': 'æ·¨é›¶æ”¿ç­–',
    'industry': 'ç”¢æ¥­åˆ†æ',
    'renewable': 'èƒ½æºç™¼å±•',
    'other': 'å…¶ä»–è­°é¡Œ',
}


def get_format_type_performance(conn) -> List[Dict]:
    """
    å–å¾—å„è²¼æ–‡å½¢å¼ (Format Type) çš„è¡¨ç¾æ¯”è¼ƒ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COALESCE(pc.format_type, pc.topic_primary, 'unclassified') as format_type,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.share_rate), 4) as avg_share_rate,
            ROUND(AVG(pp.comment_rate), 4) as avg_comment_rate,
            SUM(CASE WHEN pp.performance_tier = 'viral' THEN 1 ELSE 0 END) as viral_count,
            SUM(CASE WHEN pp.performance_tier = 'high' THEN 1 ELSE 0 END) as high_count
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY format_type
        ORDER BY avg_er DESC
    """)
    
    results = []
    for row in cursor.fetchall():
        d = dict(row)
        d['format_type_name'] = FORMAT_TYPE_NAMES.get(d['format_type'], d['format_type'])
        results.append(d)
    return results


def get_issue_topic_performance(conn) -> List[Dict]:
    """
    å–å¾—å„è­°é¡Œ (Issue Topic) çš„è¡¨ç¾æ¯”è¼ƒ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COALESCE(pc.issue_topic, pc.topic_secondary, 'unclassified') as issue_topic,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.share_rate), 4) as avg_share_rate,
            ROUND(AVG(pp.comment_rate), 4) as avg_comment_rate,
            SUM(CASE WHEN pp.performance_tier = 'viral' THEN 1 ELSE 0 END) as viral_count,
            SUM(CASE WHEN pp.performance_tier = 'high' THEN 1 ELSE 0 END) as high_count
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY issue_topic
        ORDER BY avg_er DESC
    """)
    
    results = []
    for row in cursor.fetchall():
        d = dict(row)
        d['issue_topic_name'] = ISSUE_TOPIC_NAMES.get(d['issue_topic'], d['issue_topic'])
        results.append(d)
    return results


def get_format_issue_cross_performance(conn) -> List[Dict]:
    """
    å–å¾—è²¼æ–‡å½¢å¼ Ã— è­°é¡Œçš„äº¤å‰è¡¨ç¾åˆ†æ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COALESCE(pc.format_type, pc.topic_primary, 'unclassified') as format_type,
            COALESCE(pc.issue_topic, pc.topic_secondary, 'unclassified') as issue_topic,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            ROUND(AVG(pp.share_rate), 4) as avg_share_rate,
            SUM(CASE WHEN pp.performance_tier IN ('viral', 'high') THEN 1 ELSE 0 END) as high_performer_count
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        GROUP BY format_type, issue_topic
        HAVING post_count >= 2
        ORDER BY avg_er DESC
    """)
    
    results = []
    for row in cursor.fetchall():
        d = dict(row)
        d['format_type_name'] = FORMAT_TYPE_NAMES.get(d['format_type'], d['format_type'])
        d['issue_topic_name'] = ISSUE_TOPIC_NAMES.get(d['issue_topic'], d['issue_topic'])
        results.append(d)
    return results


# ä¿ç•™èˆŠå‡½æ•¸åç¨±ä»¥ç›¸å®¹ç¾æœ‰ç¨‹å¼ç¢¼
def get_topic_performance(conn) -> List[Dict]:
    """
    å–å¾—å„ä¸»é¡Œçš„è¡¨ç¾æ¯”è¼ƒ (å‘å¾Œç›¸å®¹)
    """
    return get_format_type_performance(conn)


# ==================== é«˜è¡¨ç¾è²¼æ–‡åˆ†æ ====================

def get_top_posts(conn, days: int = 30, limit: int = 10) -> List[Dict]:
    """
    å–å¾—è¿‘æœŸè¡¨ç¾æœ€ä½³çš„è²¼æ–‡ (ä½¿ç”¨æœ€æ–° snapshot)
    """
    cursor = conn.cursor()
    cursor.execute("""
        WITH latest_insights AS (
            SELECT post_id,
                   post_impressions_unique,
                   likes_count,
                   comments_count,
                   shares_count
            FROM post_insights_snapshots
            WHERE (post_id, fetch_date) IN (
                SELECT post_id, MAX(fetch_date)
                FROM post_insights_snapshots
                GROUP BY post_id
            )
        ),
        latest_performance AS (
            SELECT post_id, engagement_rate, performance_tier, percentile_rank
            FROM posts_performance
            WHERE (post_id, snapshot_date) IN (
                SELECT post_id, MAX(snapshot_date)
                FROM posts_performance
                GROUP BY post_id
            )
        )
        SELECT
            p.post_id,
            SUBSTR(p.message, 1, 100) as message_preview,
            p.created_time,
            p.permalink_url,
            pc.topic_primary,
            pc.issue_topic,
            pc.time_slot,
            lp.engagement_rate,
            lp.performance_tier,
            lp.percentile_rank,
            li.post_impressions_unique as reach,
            li.likes_count + li.comments_count + li.shares_count as total_engagement
        FROM posts p
        JOIN posts_classification pc ON p.post_id = pc.post_id
        JOIN latest_performance lp ON p.post_id = lp.post_id
        JOIN latest_insights li ON p.post_id = li.post_id
        WHERE p.created_time >= date('now', ? || ' days')
        ORDER BY lp.engagement_rate DESC
        LIMIT ?
    """, (f'-{days}', limit))

    return [dict(row) for row in cursor.fetchall()]


def get_viral_post_patterns(conn) -> List[Dict]:
    """
    åˆ†æç—…æ¯’è²¼æ–‡çš„å…±åŒç‰¹å¾µ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            pc.media_type,
            pc.message_length_tier,
            pc.has_cta,
            pc.time_slot,
            COUNT(*) as viral_count,
            ROUND(AVG(pc.message_length), 0) as avg_length,
            ROUND(AVG(pc.hashtag_count), 1) as avg_hashtags
        FROM posts_classification pc
        JOIN posts_performance pp ON pc.post_id = pp.post_id
        WHERE pp.performance_tier = 'viral'
        GROUP BY pc.media_type, pc.message_length_tier, pc.has_cta, pc.time_slot
        ORDER BY viral_count DESC
        LIMIT 15
    """)
    
    return [dict(row) for row in cursor.fetchall()]


# ==================== è¶¨å‹¢åˆ†æ ====================

def get_weekly_trends(conn, weeks: int = 52) -> List[Dict]:
    """
    å–å¾—é€±åº¦è¶¨å‹¢ - é€±æ¬¡ä»¥é€±ä¸€ï½é€±æ—¥ç‚ºæº–
    """
    cursor = conn.cursor()
    # ä½¿ç”¨æ­£ç¢ºçš„é€±ä¸€è¨ˆç®—ï¼š
    # strftime('%w') è¿”å› 0=é€±æ—¥, 1=é€±ä¸€, ..., 6=é€±å…­
    # é€±ä¸€ = æ—¥æœŸ - ((weekday + 6) % 7) å¤©
    # 
    # ä½¿ç”¨ MAX å–å¾—å„æŒ‡æ¨™æœ€å¤§å€¼ï¼Œé¿å…ä¸å®Œæ•´ snapshot å°è‡´äº’å‹•æ•¸ç‚º 0
    cursor.execute("""
        WITH best_snapshots AS (
            SELECT post_id, 
                   MAX(post_impressions_unique) as post_impressions_unique, 
                   MAX(likes_count) as likes_count, 
                   MAX(comments_count) as comments_count, 
                   MAX(shares_count) as shares_count
            FROM post_insights_snapshots
            GROUP BY post_id
        ),
        post_weeks AS (
            SELECT 
                p.post_id,
                date(substr(p.created_time, 1, 10), 
                     '-' || ((strftime('%w', substr(p.created_time, 1, 10)) + 6) % 7) || ' days'
                ) as week_monday
            FROM posts p
        )
        SELECT
            pw.week_monday as week_start,
            date(pw.week_monday, '+6 days') as week_end,
            COUNT(DISTINCT p.post_id) as post_count,
            ROUND(AVG(pp.engagement_rate), 4) as avg_er,
            SUM(bs.post_impressions_unique) as total_reach,
            SUM(bs.likes_count + bs.comments_count + bs.shares_count) as total_engagement
        FROM posts p
        JOIN post_weeks pw ON p.post_id = pw.post_id
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN best_snapshots bs ON p.post_id = bs.post_id
        GROUP BY pw.week_monday
        ORDER BY pw.week_monday DESC
        LIMIT ?
    """, (weeks,))

    return [dict(row) for row in cursor.fetchall()]



def get_performance_distribution(conn) -> Dict:
    """
    å–å¾—è¡¨ç¾ç­‰ç´šåˆ†å¸ƒ
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            performance_tier,
            COUNT(*) as count
        FROM posts_performance
        GROUP BY performance_tier
    """)
    
    distribution = {}
    for row in cursor.fetchall():
        distribution[row['performance_tier']] = row['count']
    
    return distribution


# ==================== åŸºæº–å°ç…§ ====================

def get_benchmarks_summary(conn) -> List[Dict]:
    """
    å–å¾—æ‰€æœ‰åŸºæº–å€¼æ‘˜è¦
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            benchmark_type,
            benchmark_key,
            period,
            ROUND(avg_engagement_rate, 4) as avg_er,
            sample_size,
            updated_at
        FROM benchmarks
        ORDER BY benchmark_type, benchmark_key, period
    """)
    
    return [dict(row) for row in cursor.fetchall()]


# ==================== å ±è¡¨ç”¢å‡º ====================

def generate_weekly_report(conn) -> str:
    """
    ç”¢å‡ºé€±å ±æ–‡å­—æ‘˜è¦
    """
    report = []
    report.append("=" * 50)
    report.append(f"Facebook ç¤¾ç¾¤é€±å ± - {datetime.now().strftime('%Y-%m-%d')}")
    report.append("=" * 50)
    
    # æœ¬é€±è¡¨ç¾
    cursor = conn.cursor()
    cursor.execute("""
        SELECT 
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 2) as avg_er,
            SUM(pi.post_impressions_unique) as total_reach
        FROM posts p
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        WHERE p.created_time >= date('now', '-7 days')
    """)
    week_stats = cursor.fetchone()
    
    report.append("\nğŸ“Š æœ¬é€±æ‘˜è¦")
    report.append(f"  ç™¼æ–‡æ•¸: {week_stats['post_count'] or 0}")
    report.append(f"  å¹³å‡äº’å‹•ç‡: {week_stats['avg_er'] or 0:.2f}%")
    report.append(f"  ç¸½è§¸åŠäººæ•¸: {week_stats['total_reach'] or 0:,}")
    
    # Top 3 è²¼æ–‡
    top_posts = get_top_posts(conn, days=7, limit=3)
    report.append("\nğŸ† æœ¬é€± Top 3 è²¼æ–‡")
    for i, post in enumerate(top_posts, 1):
        msg = post['message_preview'][:50] + '...' if post['message_preview'] else '(ç„¡æ–‡å­—)'
        report.append(f"  {i}. ER={post['engagement_rate']:.2f}% | {msg}")
    
    # è¡¨ç¾åˆ†å¸ƒ
    dist = get_performance_distribution(conn)
    report.append("\nğŸ“ˆ è¡¨ç¾åˆ†å¸ƒ")
    for tier in ['viral', 'high', 'average', 'low']:
        count = dist.get(tier, 0)
        report.append(f"  {tier}: {count}")
    
    # æœ€ä½³æ™‚é–“
    best_times = get_best_posting_times(conn, limit=3)
    report.append("\nâ° æœ€ä½³ç™¼æ–‡æ™‚é–“")
    for t in best_times:
        report.append(f"  {t['day_of_week']} {t['time_slot']}: ER={t['avg_er']:.2f}%")
    
    report.append("\n" + "=" * 50)
    
    return "\n".join(report)


# ==================== ä¸»ç¨‹å¼ ====================

def main():
    """ç¤ºç¯„å ±è¡¨æŸ¥è©¢"""
    conn = get_connection()
    
    try:
        print(generate_weekly_report(conn))
        
        print("\n\n=== ä¸»é¡Œè¡¨ç¾æ¯”è¼ƒ ===")
        topics = get_topic_performance(conn)
        for t in topics:
            print(f"  {t['topic']}: ER={t['avg_er']:.2f}%, Posts={t['post_count']}")
        
        print("\n=== ç—…æ¯’è²¼æ–‡ç‰¹å¾µ ===")
        patterns = get_viral_post_patterns(conn)
        for p in patterns[:5]:
            print(f"  {p['media_type']} / {p['message_length_tier']} / CTA={p['has_cta']}: {p['viral_count']} posts")
        
    finally:
        conn.close()


if __name__ == '__main__':
    main()
