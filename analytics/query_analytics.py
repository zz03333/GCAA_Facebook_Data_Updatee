"""
Facebook ç¤¾ç¾¤æ•¸æ“šåˆ†ææ¡†æ¶ - å½ˆæ€§æŸ¥è©¢å·¥å…·
æ”¯æ´è‡ªè¨‚æ™‚é–“ç¯„åœèˆ‡ç²’åº¦çš„æ•¸æ“šæŸ¥è©¢
"""

import argparse
from datetime import datetime, timedelta
import sqlite3
from typing import List, Dict, Optional
from utils.config import DB_PATH


def get_connection():
    """å–å¾—è³‡æ–™åº«é€£ç·š"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


# ==================== æ™‚é–“ç¯„åœæŸ¥è©¢ ====================

def query_by_date_range(conn, start_date: str, end_date: str, granularity: str = 'daily') -> List[Dict]:
    """
    ä¾æ—¥æœŸç¯„åœæŸ¥è©¢æ•¸æ“š

    Args:
        start_date: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        granularity: ç²’åº¦ (daily/weekly/monthly)

    Returns:
        æŸ¥è©¢çµæœåˆ—è¡¨
    """
    cursor = conn.cursor()

    # æ ¹æ“šç²’åº¦é¸æ“‡ä¸åŒçš„æ™‚é–“åˆ†çµ„
    # æ³¨æ„: created_time æ ¼å¼ç‚º '2025-12-11T01:30:00+0000'ï¼Œéœ€å…ˆç§»é™¤æ™‚å€
    if granularity == 'daily':
        time_format = "%Y-%m-%d"
        group_by = "SUBSTR(p.created_time, 1, 10)"
    elif granularity == 'weekly':
        time_format = "%Y-W%W"
        group_by = "strftime('%Y-W%W', SUBSTR(p.created_time, 1, 19))"
    elif granularity == 'monthly':
        time_format = "%Y-%m"
        group_by = "SUBSTR(p.created_time, 1, 7)"
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„ç²’åº¦: {granularity}")

    query = f"""
        SELECT
            {"strftime('" + time_format + "', SUBSTR(p.created_time, 1, 19))" if granularity in ['weekly'] else group_by} as time_period,
            COUNT(DISTINCT p.post_id) as post_count,

            -- äº’å‹•æŒ‡æ¨™
            SUM(pi.likes_count) as total_likes,
            SUM(pi.comments_count) as total_comments,
            SUM(pi.shares_count) as total_shares,
            SUM(pi.likes_count + pi.comments_count + pi.shares_count) as total_engagement,

            -- è§¸åŠæŒ‡æ¨™
            SUM(pi.post_impressions_unique) as total_reach,
            SUM(pi.post_clicks) as total_clicks,

            -- å¹³å‡ KPI
            ROUND(AVG(pp.engagement_rate), 2) as avg_engagement_rate,
            ROUND(AVG(pp.click_through_rate), 2) as avg_click_rate,
            ROUND(AVG(pp.share_rate), 2) as avg_share_rate,
            ROUND(AVG(pp.comment_rate), 2) as avg_comment_rate,

            -- è¡¨ç¾åˆ†ç´šçµ±è¨ˆ
            SUM(CASE WHEN pp.performance_tier = 'viral' THEN 1 ELSE 0 END) as viral_count,
            SUM(CASE WHEN pp.performance_tier = 'high' THEN 1 ELSE 0 END) as high_count,
            SUM(CASE WHEN pp.performance_tier = 'average' THEN 1 ELSE 0 END) as average_count,
            SUM(CASE WHEN pp.performance_tier = 'low' THEN 1 ELSE 0 END) as low_count

        FROM posts p
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        JOIN posts_performance pp ON p.post_id = pp.post_id
        WHERE SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?
        GROUP BY {group_by}
        ORDER BY time_period DESC
    """

    cursor.execute(query, (start_date, end_date))
    return [dict(row) for row in cursor.fetchall()]


def query_topic_performance(conn, start_date: str, end_date: str, topic: Optional[str] = None) -> List[Dict]:
    """
    æŸ¥è©¢ä¸»é¡Œè¡¨ç¾ï¼ˆå¯æŒ‡å®šæ™‚é–“ç¯„åœï¼‰

    Args:
        start_date: èµ·å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        topic: ç‰¹å®šä¸»é¡Œ (å¯é¸)
    """
    cursor = conn.cursor()

    where_clause = "WHERE SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?"
    params = [start_date, end_date]

    if topic:
        where_clause += " AND pc.topic_primary = ?"
        params.append(topic)

    query = f"""
        SELECT
            COALESCE(pc.topic_primary, 'unclassified') as topic,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 2) as avg_engagement_rate,
            ROUND(AVG(pp.share_rate), 2) as avg_share_rate,
            ROUND(AVG(pp.comment_rate), 2) as avg_comment_rate,
            SUM(CASE WHEN pp.performance_tier = 'viral' THEN 1 ELSE 0 END) as viral_count,
            SUM(CASE WHEN pp.performance_tier = 'high' THEN 1 ELSE 0 END) as high_count,
            SUM(pi.post_impressions_unique) as total_reach,
            SUM(pi.likes_count + pi.comments_count + pi.shares_count) as total_engagement
        FROM posts p
        JOIN posts_classification pc ON p.post_id = pc.post_id
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        {where_clause}
        GROUP BY pc.topic_primary
        ORDER BY avg_engagement_rate DESC
    """

    cursor.execute(query, params)
    return [dict(row) for row in cursor.fetchall()]


def query_time_slot_performance(conn, start_date: str, end_date: str) -> List[Dict]:
    """
    æŸ¥è©¢æ™‚æ®µè¡¨ç¾ï¼ˆå¯æŒ‡å®šæ™‚é–“ç¯„åœï¼‰
    """
    cursor = conn.cursor()

    query = """
        SELECT
            pc.time_slot,
            CASE pc.day_of_week
                WHEN 0 THEN 'Mon'
                WHEN 1 THEN 'Tue'
                WHEN 2 THEN 'Wed'
                WHEN 3 THEN 'Thu'
                WHEN 4 THEN 'Fri'
                WHEN 5 THEN 'Sat'
                WHEN 6 THEN 'Sun'
            END as day_of_week,
            COUNT(*) as post_count,
            ROUND(AVG(pp.engagement_rate), 2) as avg_engagement_rate,
            ROUND(AVG(pp.click_through_rate), 2) as avg_click_rate,
            SUM(pi.post_impressions_unique) as total_reach
        FROM posts p
        JOIN posts_classification pc ON p.post_id = pc.post_id
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        WHERE SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?
        GROUP BY pc.time_slot, pc.day_of_week
        HAVING post_count >= 2
        ORDER BY avg_engagement_rate DESC
    """

    cursor.execute(query, (start_date, end_date))
    return [dict(row) for row in cursor.fetchall()]


def query_top_posts(conn, start_date: str, end_date: str, limit: int = 10,
                    topic: Optional[str] = None, time_slot: Optional[str] = None) -> List[Dict]:
    """
    æŸ¥è©¢ Top è²¼æ–‡ï¼ˆæ”¯æ´ç¯©é¸æ¢ä»¶ï¼‰

    Args:
        start_date: èµ·å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        limit: å›å‚³æ•¸é‡
        topic: ç¯©é¸ä¸»é¡Œ (å¯é¸)
        time_slot: ç¯©é¸æ™‚æ®µ (å¯é¸)
    """
    cursor = conn.cursor()

    where_clauses = ["SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?"]
    params = [start_date, end_date]

    if topic:
        where_clauses.append("pc.topic_primary = ?")
        params.append(topic)

    if time_slot:
        where_clauses.append("pc.time_slot = ?")
        params.append(time_slot)

    where_clause = " AND ".join(where_clauses)
    params.append(limit)

    query = f"""
        SELECT
            p.post_id,
            SUBSTR(p.message, 1, 100) as message_preview,
            p.created_time,
            pc.topic_primary,
            pc.time_slot,
            pp.engagement_rate,
            pp.performance_tier,
            pp.percentile_rank,
            pi.post_impressions_unique as reach,
            (pi.likes_count + pi.comments_count + pi.shares_count) as total_engagement,
            pi.likes_count,
            pi.comments_count,
            pi.shares_count
        FROM posts p
        JOIN posts_classification pc ON p.post_id = pc.post_id
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        WHERE {where_clause}
        ORDER BY pp.engagement_rate DESC
        LIMIT ?
    """

    cursor.execute(query, params)
    return [dict(row) for row in cursor.fetchall()]


def query_comparison(conn, period1_start: str, period1_end: str,
                     period2_start: str, period2_end: str) -> Dict:
    """
    æ¯”è¼ƒå…©å€‹æ™‚é–“æ®µçš„è¡¨ç¾

    Args:
        period1_start: æœŸé–“1èµ·å§‹
        period1_end: æœŸé–“1çµæŸ
        period2_start: æœŸé–“2èµ·å§‹
        period2_end: æœŸé–“2çµæŸ

    Returns:
        åŒ…å«å…©æœŸæ¯”è¼ƒçš„å­—å…¸
    """
    cursor = conn.cursor()

    query = """
        SELECT
            COUNT(*) as post_count,
            SUM(pi.post_impressions_unique) as total_reach,
            SUM(pi.likes_count + pi.comments_count + pi.shares_count) as total_engagement,
            ROUND(AVG(pp.engagement_rate), 2) as avg_engagement_rate,
            SUM(CASE WHEN pp.performance_tier = 'viral' THEN 1 ELSE 0 END) as viral_count,
            SUM(CASE WHEN pp.performance_tier = 'high' THEN 1 ELSE 0 END) as high_count
        FROM posts p
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        WHERE SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?
    """

    # æŸ¥è©¢æœŸé–“1
    cursor.execute(query, (period1_start, period1_end))
    period1 = dict(cursor.fetchone())

    # æŸ¥è©¢æœŸé–“2
    cursor.execute(query, (period2_start, period2_end))
    period2 = dict(cursor.fetchone())

    # è¨ˆç®—è®ŠåŒ–
    result = {
        'period1': {
            'start': period1_start,
            'end': period1_end,
            **period1
        },
        'period2': {
            'start': period2_start,
            'end': period2_end,
            **period2
        },
        'changes': {}
    }

    # è¨ˆç®—å„é …è®ŠåŒ–ç™¾åˆ†æ¯”
    for key in ['post_count', 'total_reach', 'total_engagement', 'avg_engagement_rate']:
        val1 = period1[key] or 0
        val2 = period2[key] or 0

        if val2 > 0:
            change_pct = ((val1 - val2) / val2) * 100
            result['changes'][key] = round(change_pct, 1)
        else:
            result['changes'][key] = None

    return result


# ==================== å ±è¡¨ç”¢å‡º ====================

def generate_custom_report(conn, start_date: str, end_date: str, granularity: str = 'weekly') -> str:
    """
    ç”¢å‡ºè‡ªè¨‚æ™‚é–“ç¯„åœçš„å ±è¡¨
    """
    report = []
    report.append("=" * 70)
    report.append(f"Facebook ç¤¾ç¾¤åˆ†æå ±è¡¨")
    report.append(f"æ™‚é–“ç¯„åœ: {start_date} ~ {end_date}")
    report.append(f"ç²’åº¦: {granularity}")
    report.append(f"ç”¢å‡ºæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("=" * 70)

    # æ•´é«”æ‘˜è¦
    cursor = conn.cursor()
    cursor.execute("""
        SELECT
            COUNT(*) as post_count,
            SUM(pi.post_impressions_unique) as total_reach,
            SUM(pi.likes_count + pi.comments_count + pi.shares_count) as total_engagement,
            ROUND(AVG(pp.engagement_rate), 2) as avg_engagement_rate
        FROM posts p
        JOIN posts_performance pp ON p.post_id = pp.post_id
        JOIN post_insights_snapshots pi ON p.post_id = pi.post_id
        WHERE SUBSTR(p.created_time, 1, 10) BETWEEN ? AND ?
    """, (start_date, end_date))

    summary = cursor.fetchone()

    report.append("\nğŸ“Š æ•´é«”æ‘˜è¦")
    report.append(f"  ç™¼æ–‡ç¸½æ•¸: {summary['post_count'] or 0}")
    report.append(f"  ç¸½è§¸åŠäººæ•¸: {summary['total_reach'] or 0:,}")
    report.append(f"  ç¸½äº’å‹•æ•¸: {summary['total_engagement'] or 0:,}")
    report.append(f"  å¹³å‡äº’å‹•ç‡: {summary['avg_engagement_rate'] or 0:.2f}%")

    # æ™‚é–“è¶¨å‹¢
    trends = query_by_date_range(conn, start_date, end_date, granularity)

    report.append(f"\nğŸ“ˆ {granularity.capitalize()} è¶¨å‹¢")
    report.append(f"{'æ™‚æœŸ':15s} {'è²¼æ–‡æ•¸':>8s} {'è§¸åŠ':>10s} {'äº’å‹•ç‡':>10s} {'Viral':>6s}")
    report.append("-" * 70)

    for row in trends[:10]:  # åªé¡¯ç¤ºæœ€è¿‘10æœŸ
        report.append(
            f"{row['time_period']:15s} "
            f"{row['post_count']:8d} "
            f"{row['total_reach']:10,d} "
            f"{row['avg_engagement_rate']:9.2f}% "
            f"{row['viral_count']:6d}"
        )

    # ä¸»é¡Œè¡¨ç¾
    topics = query_topic_performance(conn, start_date, end_date)

    report.append("\nğŸ¯ ä¸»é¡Œè¡¨ç¾")
    for topic in topics[:5]:
        report.append(
            f"  {topic['topic']:15s}: "
            f"ER={topic['avg_engagement_rate']:5.2f}%, "
            f"Posts={topic['post_count']}, "
            f"Viral={topic['viral_count']}"
        )

    # æœ€ä½³ç™¼æ–‡æ™‚é–“
    time_slots = query_time_slot_performance(conn, start_date, end_date)

    report.append("\nâ° æœ€ä½³ç™¼æ–‡æ™‚é–“ (Top 5)")
    for slot in time_slots[:5]:
        report.append(
            f"  {slot['day_of_week']:3s} {slot['time_slot']:10s}: "
            f"ER={slot['avg_engagement_rate']:5.2f}%, "
            f"Posts={slot['post_count']}"
        )

    # Top è²¼æ–‡
    top_posts = query_top_posts(conn, start_date, end_date, limit=3)

    report.append("\nğŸ† Top 3 è²¼æ–‡")
    for i, post in enumerate(top_posts, 1):
        msg = (post['message_preview'] or '')[:50]
        report.append(f"  {i}. ER={post['engagement_rate']:.2f}% | {msg}...")

    report.append("\n" + "=" * 70)

    return "\n".join(report)


# ==================== å‘½ä»¤åˆ—ä»‹é¢ ====================

def main():
    """å‘½ä»¤åˆ—åŸ·è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description='Facebook ç¤¾ç¾¤æ•¸æ“šåˆ†æ - å½ˆæ€§æŸ¥è©¢å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:

  # æŸ¥è©¢æœ€è¿‘ 7 å¤©çš„æ¯æ—¥æ•¸æ“š
  python3 query_analytics.py --days 7 --granularity daily

  # æŸ¥è©¢ç‰¹å®šæ™‚é–“ç¯„åœçš„é€±åº¦æ•¸æ“š
  python3 query_analytics.py --start 2025-11-01 --end 2025-11-30 --granularity weekly

  # æŸ¥è©¢ç‰¹å®šä¸»é¡Œçš„è¡¨ç¾
  python3 query_analytics.py --days 30 --topic energy

  # æ¯”è¼ƒå…©å€‹æ™‚é–“æ®µ
  python3 query_analytics.py --compare --period1 2025-10-01,2025-10-31 --period2 2025-11-01,2025-11-30

  # æŸ¥è©¢ç‰¹å®šæ™‚æ®µçš„ Top è²¼æ–‡
  python3 query_analytics.py --days 30 --top 10 --time-slot evening

        """
    )

    # æ™‚é–“ç¯„åœé¸é …
    time_group = parser.add_mutually_exclusive_group()
    time_group.add_argument('--days', type=int, help='æŸ¥è©¢æœ€è¿‘ N å¤©')
    time_group.add_argument('--weeks', type=int, help='æŸ¥è©¢æœ€è¿‘ N é€±')
    time_group.add_argument('--months', type=int, help='æŸ¥è©¢æœ€è¿‘ N å€‹æœˆ')

    parser.add_argument('--start', help='èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end', help='çµæŸæ—¥æœŸ (YYYY-MM-DD)')

    # ç²’åº¦é¸é …
    parser.add_argument('--granularity', choices=['daily', 'weekly', 'monthly'],
                        default='weekly', help='æ•¸æ“šç²’åº¦ (é è¨­: weekly)')

    # ç¯©é¸é¸é …
    parser.add_argument('--topic', help='ç¯©é¸ç‰¹å®šä¸»é¡Œ')
    parser.add_argument('--time-slot',
                        choices=['morning', 'noon', 'afternoon', 'evening', 'night'],
                        help='ç¯©é¸ç‰¹å®šæ™‚æ®µ')

    # æŸ¥è©¢é¡å‹
    parser.add_argument('--top', type=int, metavar='N', help='é¡¯ç¤º Top N è²¼æ–‡')
    parser.add_argument('--compare', action='store_true', help='æ¯”è¼ƒå…©å€‹æ™‚é–“æ®µ')
    parser.add_argument('--period1', help='æ¯”è¼ƒæœŸé–“1 (start,end)')
    parser.add_argument('--period2', help='æ¯”è¼ƒæœŸé–“2 (start,end)')

    # è¼¸å‡ºé¸é …
    parser.add_argument('--format', choices=['text', 'json'], default='text',
                        help='è¼¸å‡ºæ ¼å¼ (é è¨­: text)')

    args = parser.parse_args()

    # è¨ˆç®—æ™‚é–“ç¯„åœ
    if args.start and args.end:
        start_date = args.start
        end_date = args.end
    elif args.days:
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=args.days)).strftime('%Y-%m-%d')
    elif args.weeks:
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(weeks=args.weeks)).strftime('%Y-%m-%d')
    elif args.months:
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=args.months*30)).strftime('%Y-%m-%d')
    else:
        # é è¨­æœ€è¿‘ 7 å¤©
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')

    # åŸ·è¡ŒæŸ¥è©¢
    conn = get_connection()

    try:
        if args.compare:
            # æ¯”è¼ƒæ¨¡å¼
            if not (args.period1 and args.period2):
                print("éŒ¯èª¤: æ¯”è¼ƒæ¨¡å¼éœ€è¦ --period1 å’Œ --period2 åƒæ•¸")
                print("ç¯„ä¾‹: --period1 2025-10-01,2025-10-31 --period2 2025-11-01,2025-11-30")
                return

            p1_start, p1_end = args.period1.split(',')
            p2_start, p2_end = args.period2.split(',')

            result = query_comparison(conn, p1_start, p1_end, p2_start, p2_end)

            if args.format == 'json':
                import json
                print(json.dumps(result, indent=2, ensure_ascii=False))
            else:
                print("\n" + "="*60)
                print("æ™‚é–“æ®µæ¯”è¼ƒåˆ†æ")
                print("="*60)
                print(f"\næœŸé–“1: {p1_start} ~ {p1_end}")
                print(f"  ç™¼æ–‡æ•¸: {result['period1']['post_count']}")
                print(f"  ç¸½è§¸åŠ: {result['period1']['total_reach']:,}")
                print(f"  å¹³å‡ER: {result['period1']['avg_engagement_rate']}%")

                print(f"\næœŸé–“2: {p2_start} ~ {p2_end}")
                print(f"  ç™¼æ–‡æ•¸: {result['period2']['post_count']}")
                print(f"  ç¸½è§¸åŠ: {result['period2']['total_reach']:,}")
                print(f"  å¹³å‡ER: {result['period2']['avg_engagement_rate']}%")

                print("\nğŸ“Š è®ŠåŒ–")
                for key, value in result['changes'].items():
                    if value is not None:
                        symbol = "ğŸ“ˆ" if value > 0 else "ğŸ“‰" if value < 0 else "â†’"
                        print(f"  {symbol} {key}: {value:+.1f}%")
                print()

        elif args.top:
            # Top è²¼æ–‡æŸ¥è©¢
            posts = query_top_posts(conn, start_date, end_date, args.top, args.topic, args.time_slot)

            if args.format == 'json':
                import json
                print(json.dumps(posts, indent=2, ensure_ascii=False))
            else:
                print(f"\n{'='*70}")
                print(f"Top {args.top} è²¼æ–‡ ({start_date} ~ {end_date})")
                if args.topic:
                    print(f"ä¸»é¡Œç¯©é¸: {args.topic}")
                if args.time_slot:
                    print(f"æ™‚æ®µç¯©é¸: {args.time_slot}")
                print("="*70)

                for i, post in enumerate(posts, 1):
                    print(f"\n{i}. ER: {post['engagement_rate']:.2f}% | Tier: {post['performance_tier']}")
                    print(f"   ç™¼å¸ƒ: {post['created_time'][:10]} | ä¸»é¡Œ: {post['topic_primary'] or 'N/A'} | æ™‚æ®µ: {post['time_slot']}")
                    print(f"   è§¸åŠ: {post['reach']:,} | äº’å‹•: {post['total_engagement']} (ğŸ‘{post['likes_count']} ğŸ’¬{post['comments_count']} ğŸ”—{post['shares_count']})")
                    print(f"   å…§å®¹: {post['message_preview']}...")
                print()

        else:
            # ä¸€èˆ¬å ±è¡¨
            report = generate_custom_report(conn, start_date, end_date, args.granularity)

            if args.format == 'json':
                # JSON æ ¼å¼è¼¸å‡º
                data = {
                    'trends': query_by_date_range(conn, start_date, end_date, args.granularity),
                    'topics': query_topic_performance(conn, start_date, end_date, args.topic),
                    'time_slots': query_time_slot_performance(conn, start_date, end_date)
                }
                import json
                print(json.dumps(data, indent=2, ensure_ascii=False))
            else:
                print(report)

    finally:
        conn.close()


if __name__ == '__main__':
    main()
